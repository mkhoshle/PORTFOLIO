{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import distance\n",
    "import re, sys, os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from IPython.display import display\n",
    "import seaborn.apionly as sns\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style('ticks')\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from torchvision import datasets\n",
    "from IPython.display import Image\n",
    "import h5py\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano import pp\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from skimage import io\n",
    "import argparse\n",
    "import scipy.io as sio\n",
    "\n",
    "# Enable inline plotting  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/Users/mahzadkhoshlessan/Desktop/Machine-Learning/Intro-to-Deep-Learning/Final_Project/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_Model import project_01, normalize_im, NeuralNet, L1L2loss, weight_init, Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'ArtificialDataset.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = io.imread(datafile)\n",
    "(K, M, N) = Images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampling_factor = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampling using a simple nearest neighbor interp.\n",
    "Images_upsampled = np.zeros((K, M*upsampling_factor, N*upsampling_factor))\n",
    "for i in range(Images.shape[0]):\n",
    "    Images_upsampled[i,:,:] = np.kron(Images[i,:,:], np.ones((upsampling_factor,upsampling_factor)))   \n",
    "Images = Images_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampled frames dimensions\n",
    "(K, M, N) = Images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(myModel.parameters(), lr=0.001)\n",
    "criterion = L1L2loss((1, M, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = os.path.abspath(os.path.normpath(os.path.join(os.getcwd(),'Checkpointer.h5')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.load_state_dict(checkpoint['state_dict'])\n",
    "myModel.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mean and std\n",
    "matfile = sio.loadmat(meanstd_file)\n",
    "test_mean = np.array(matfile['mean_test'])\n",
    "test_std = np.array(matfile['std_test'])   \n",
    "\n",
    "# Setting type\n",
    "Images = Images.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each sample by it's own mean and std\n",
    "Images_norm = np.zeros(Images.shape,dtype=np.float32)\n",
    "for i in range(Images.shape[0]):\n",
    "    Images_norm[i,:,:] = project_01(Images[i,:,:])\n",
    "    Images_norm[i,:,:] = normalize_im(Images_norm[i,:,:], test_mean, test_std)\n",
    "\n",
    "# Reshaping\n",
    "Images_norm = np.expand_dims(Images_norm,axis=3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "predicted_density = myModel(Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold negative values\n",
    "predicted_density[predicted_density < 0] = 0\n",
    "\n",
    "# resulting sum images\n",
    "WideField = np.squeeze(np.sum(Images_norm, axis=0))\n",
    "Recovery = np.squeeze(np.sum(predicted_density, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the sum image\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "ax1.imshow(WideField)\n",
    "ax1.set_title('Wide Field')\n",
    "ax2.imshow(Recovery)\n",
    "ax2.set_title('Sum of Predictions')\n",
    "f.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to a matfile to open later in matlab\n",
    "mdict = {\"Recovery\": Recovery}\n",
    "sio.savemat(savename, mdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predicted density in each frame for debugging purposes\n",
    "mdict = {\"Predictions\": predicted_density}\n",
    "sio.savemat(savename + '_predictions.mat', mdict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
